# Sign-Bridge a sign Language Interpretation for Deaf and Mute 

## Overview
This project aims to develop a system for interpreting sign language gestures to text or speech for communication with deaf and mute individuals. It utilizes LSTM (Long Short-Term Memory) networks for gesture recognition and MediaPipe for hand tracking and landmark detection.

## Requirements
- Python 3.x
- TensorFlow
- MediaPipe
- opencv

## Installation
1. Clone the repository: `https://github.com/abhi107d/sign_bridge.git`
2. Install the dependencies: `pip install -r requirements.txt`

## Usage
1. Prepare your dataset or use a pre-existing dataset.
2. Train the LSTM model using the dataset.
3. Use the trained model for sign language interpretation.


