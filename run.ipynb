{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2963032c-639d-46fd-a5b8-e60e71ab4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9827c2b-732f-44d3-806b-dfb5fc7b5ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12092dc1-65b3-40bb-9ca0-c951a1a75962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def draw(frame,landmarks,mp_draw,mp_hol):\n",
    "        mp_draw.draw_landmarks(frame,landmarks.face_landmarks,mp_hol.FACEMESH_CONTOURS,\n",
    "                              mp_draw.DrawingSpec(color=(98,226,34), thickness=1, circle_radius=1),\n",
    "                              mp_draw.DrawingSpec(color=(238,38,211), thickness=2, circle_radius=1))\n",
    "        mp_draw.draw_landmarks(frame,landmarks.left_hand_landmarks,mp_hol.HAND_CONNECTIONS,\n",
    "                              mp_draw.DrawingSpec(color=(238,231,38), thickness=4, circle_radius=4),\n",
    "                              mp_draw.DrawingSpec(color=(238,38,211), thickness=4, circle_radius=4))\n",
    "        mp_draw.draw_landmarks(frame,landmarks.right_hand_landmarks,mp_hol.HAND_CONNECTIONS,\n",
    "                              mp_draw.DrawingSpec(color=(238,231,38), thickness=4, circle_radius=4),\n",
    "                              mp_draw.DrawingSpec(color=(238,38,211), thickness=4, circle_radius=4))\n",
    "        mp_draw.draw_landmarks(frame,landmarks.pose_landmarks,mp_hol.POSE_CONNECTIONS,\n",
    "                              mp_draw.DrawingSpec(color=(98,226,34), thickness=3, circle_radius=4),\n",
    "                              mp_draw.DrawingSpec(color=(238,38,211), thickness=4, circle_radius=4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4c5f3a-a61c-4984-8c12-af18cddf8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_landmarks(landmarks):\n",
    "    if landmarks.pose_landmarks:\n",
    "        pose=np.array([[p.x,p.y,p.z,p.visibility] for p in landmarks.pose_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        pose=np.zeros(132,)\n",
    "    if landmarks.left_hand_landmarks:\n",
    "        left_hand=np.array([[p.x,p.y,p.z] for p in landmarks.left_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        left_hand=np.zeros(63,)\n",
    "    if landmarks.right_hand_landmarks:\n",
    "        right_hand=np.array([[p.x,p.y,p.z] for p in landmarks.right_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        right_hand=np.zeros(63,)\n",
    "    if landmarks.face_landmarks:\n",
    "        face=np.array([[p.x,p.y,p.z] for p in landmarks.face_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        face=np.zeros(1404,)\n",
    "\n",
    "    return np.concatenate([face,pose,left_hand,right_hand])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b912b41-a522-476d-ac13-3df5d03163e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_map=[\"idel\",\"hello\",\"thanks\"]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(29,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.load_weights(os.path.join(\"models\",\"main.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa682e0-d226-4fc9-a2b0-150fe636310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "mp_hol=mp.solutions.holistic\n",
    "mp_draw=mp.solutions.drawing_utils\n",
    "#just capture\n",
    "cam=cv2.VideoCapture(0)\n",
    "action=[]\n",
    "text=[]\n",
    "# predictions = []\n",
    "trsh=0.4\n",
    "res=np.array([0,0])\n",
    "\n",
    "with mp_hol.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as hol:\n",
    "    while cam.isOpened():\n",
    "        ret,frame=cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        landmarks=hol.process(image)\n",
    "\n",
    "        points=extract_landmarks(landmarks)\n",
    "\n",
    "        #getting 30 frames of action\n",
    "        action.append(points)\n",
    "        action=action[-29:]\n",
    "        if len(action)==29:\n",
    "            res=model.predict(np.expand_dims(action,axis=0))[0]\n",
    "            # predictions.append(np.argmax(res))\n",
    "            p_idx=np.argmax(res)\n",
    "            # predictions=predictions[-10:]\n",
    "            # print(predictions)\n",
    "            # if np.unique(predictions)[-1]==np.argmax(res): \n",
    "               \n",
    "            if  res[p_idx]>trsh:\n",
    "                if len(text)>0:\n",
    "                    if label_map[p_idx]!=text[-1]:\n",
    "                        text.append(label_map[p_idx])\n",
    "                else:\n",
    "                    text.append(label_map[p_idx])\n",
    "\n",
    "                \n",
    "            \n",
    "            if len(text)>5:\n",
    "                text=text[-5:]\n",
    "                \n",
    "                \n",
    "              \n",
    "           \n",
    "        #drawing on image\n",
    "        draw(frame,landmarks,mp_draw,mp_hol)\n",
    "        frame=cv2.flip(frame,1)\n",
    "\n",
    "        cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(frame, ' '.join(text), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"capture\",frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fcd6a3-d7dd-46cf-927a-16ae2c7e51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b98742-490c-4f38-b96f-ddb042ccc781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
